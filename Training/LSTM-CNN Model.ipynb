{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import string\n",
    "\n",
    "##########################\n",
    "#### Helper Functions ####\n",
    "##########################\n",
    "def getCleanDataPath(filename):\n",
    "    return os.path.join(\"C:\\\\\", \"Users\", \"liqhtninq\", \"Documents\", \"Sentiment Analysis Model\", \"Clean Data\", filename)\n",
    "\n",
    "def getModelPath(filename):\n",
    "    return os.path.join(\"C:\\\\\", \"Users\", \"liqhtninq\", \"Documents\", \"Sentiment Analysis Model\", \"Models\", filename)\n",
    "\n",
    "def readPkl(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def getWordCounts(data):\n",
    "    wordCount = defaultdict(int)\n",
    "    for d in data:\n",
    "        r = ''.join([c for c in d.lower() if not c in set(string.punctuation)])\n",
    "        seen = []\n",
    "        for w in r.split():\n",
    "            wordCount[w] += 1\n",
    "            if w not in seen:\n",
    "                seen.append(w)\n",
    "    counts = [(wordCount[w], w) for w in wordCount]\n",
    "    counts.sort()\n",
    "    counts.reverse()\n",
    "    return counts\n",
    "\n",
    "def assignIds(counts, numWords):\n",
    "    words = [x[1] for x in counts[:numWords]]\n",
    "    return dict(zip(words, range(len(words))))\n",
    "\n",
    "def parseFeaturesFromText(data, wordId):\n",
    "    X = []\n",
    "    for d in data:\n",
    "        r = ''.join([c for c in d.lower() if not c in set(string.punctuation)])\n",
    "        split = r.split()\n",
    "        vec = []\n",
    "        for w in split:\n",
    "            if w in wordId:\n",
    "                vec.append(wordId[w])\n",
    "        X.append(vec)\n",
    "    return X\n",
    "\n",
    "def getMaxLength(data):\n",
    "    m = 0\n",
    "    for d in data:\n",
    "        m = max(m, len(d))\n",
    "    return m\n",
    "\n",
    "def saveAsPkl(file, data):\n",
    "    with open(file, 'wb') as f:\n",
    "        pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "#### Define Data ####\n",
    "#####################\n",
    "\n",
    "featuresFileName = 'Amazon Electronics Reiviews Text.pkl'\n",
    "targetFileName = 'Amazon Electronics Reiviews Ratings.pkl'\n",
    "\n",
    "features = readPkl(getCleanDataPath(featuresFileName))\n",
    "targets = readPkl(getCleanDataPath(targetFileName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "#### Parse the data into something usable ####\n",
    "##############################################\n",
    "n_samples = 100000\n",
    "num_words = 2000\n",
    "\n",
    "X = features[:n_samples]\n",
    "y = targets[:n_samples]\n",
    "\n",
    "counts = getWordCounts(X)\n",
    "wordIds = assignIds(counts, num_words)\n",
    "X = parseFeaturesFromText(X, wordIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "########################################\n",
    "#### Split data into train and test ####\n",
    "########################################\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "max_review_length = getMaxLength(X)\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 2917, 512)         1024000   \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 2917, 32)          131104    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 729, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 729, 16)           2064      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 364, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 364, 8)            520       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 182, 8)            0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 512)               1067008   \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,651,705\n",
      "Trainable params: 2,651,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/3\n",
      "80000/80000 [==============================] - 6970s 87ms/step - loss: 0.4705 - acc: 0.8119 - val_loss: 0.3671 - val_acc: 0.8435\n",
      "Epoch 2/3\n",
      "80000/80000 [==============================] - 7070s 88ms/step - loss: 0.3252 - acc: 0.8633 - val_loss: 0.3298 - val_acc: 0.8633\n",
      "Epoch 3/3\n",
      "80000/80000 [==============================] - 7083s 89ms/step - loss: 0.2833 - acc: 0.8848 - val_loss: 0.3046 - val_acc: 0.8713\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "#### Define Model ####\n",
    "###################### \n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "### Model Parameters ###\n",
    "embedding_vecor_length = 512\n",
    "num_cnn_filters = [32,16,8]\n",
    "cnn_kernel_size = [8,4,4]\n",
    "pool_size = [4,2,2]\n",
    "LSTM_length = 512\n",
    "n_categories = 1\n",
    "activation_function = 'sigmoid'\n",
    "loss_function = 'binary_crossentropy'\n",
    "dense_layers=[512,256,128]\n",
    "lstm_dropout = 0.05\n",
    "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "### Models ### \n",
    "def buildLSTMCNNModel():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(num_words, embedding_vecor_length, input_length=max_review_length))\n",
    "    model.add(Conv1D(filters=num_cnn_filters[0], kernel_size=cnn_kernel_size[0], padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=pool_size[0]))\n",
    "    model.add(Conv1D(filters=num_cnn_filters[1], kernel_size=cnn_kernel_size[1], padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=pool_size[1]))\n",
    "    model.add(Conv1D(filters=num_cnn_filters[2], kernel_size=cnn_kernel_size[2], padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=pool_size[2]))\n",
    "    model.add(LSTM(LSTM_length, dropout=lstm_dropout))\n",
    "    model.add(Dense(dense_layers[0], activation='relu'))\n",
    "    model.add(Dense(dense_layers[1], activation='relu'))\n",
    "    model.add(Dense(dense_layers[2], activation='relu')) \n",
    "    model.add(Dense(n_categories, activation=activation_function))\n",
    "    model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    model = buildLSTMCNNModel()\n",
    "    print(model.summary())\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "#### Save The Model ####\n",
    "########################\n",
    "\n",
    "model_name = \"LSTM_CNN_Electronics.pkl\"\n",
    "\n",
    "saveAsPkl(getModelPath(model_name), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
